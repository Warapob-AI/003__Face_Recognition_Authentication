{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "prototxt_path = \"deploy.prototxt\"\n",
    "model_path = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "face_net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(image):\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300),\n",
    "                                 mean=(104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "    face_net.setInput(blob)\n",
    "    detections = face_net.forward()\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.2:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "\n",
    "            padding = 20\n",
    "            x1, y1, x2, y2 = max(0, x1 - padding), max(0, y1 - padding), min(w, x2 + padding), min(h, y2 + padding)\n",
    "\n",
    "            face = image[y1:y2, x1:x2]\n",
    "            return face \n",
    "\n",
    "    return None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    image = cv2.resize(image, (256, 256)) \n",
    "    \n",
    "    try:\n",
    "        features = DeepFace.represent(image, model_name=\"Facenet\", enforce_detection=False)\n",
    "        # print(\"üìå Features Output:\", features)\n",
    "        \n",
    "        if isinstance(features, list) and len(features) > 0:\n",
    "            return np.array(features[0]['embedding'])\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No embedding found\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error extracting features: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_path = \"face_database.db\"\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        firstname TEXT,\n",
    "        lastname TEXT,\n",
    "        embedding BLOB\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    l = clahe.apply(l)\n",
    "    lab = cv2.merge((l, a, b))\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def shear_image(image, shear_factor=0.2):\n",
    "    height, width = image.shape[:2]\n",
    "    M = np.float32([[1, shear_factor, 0], [shear_factor, 1, 0]])\n",
    "    return cv2.warpAffine(image, M, (width, height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(detect_image):\n",
    "    features = []\n",
    "    transformations = {\n",
    "        \"original\": detect_image,\n",
    "        \"flipped\": cv2.flip(detect_image, 1),\n",
    "        \"rotated\": cv2.warpAffine(detect_image, cv2.getRotationMatrix2D((detect_image.shape[1]//2, detect_image.shape[0]//2), 15, 1), (detect_image.shape[1], detect_image.shape[0])),\n",
    "        \"stretched\": cv2.resize(cv2.resize(detect_image, (int(detect_image.shape[1] * 1.05), detect_image.shape[0])), (detect_image.shape[1], detect_image.shape[0])),\n",
    "        \"blurred\": cv2.GaussianBlur(detect_image, (5,5), 0),\n",
    "        \"clahe\": apply_clahe(detect_image),\n",
    "        \"sheared\": shear_image(detect_image, 0.2)\n",
    "    }\n",
    "    \n",
    "    for name, img in transformations.items():\n",
    "        feature = extract_features(img)\n",
    "        if feature is not None:\n",
    "            features.append(feature)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_face(firstname, lastname, image_path):\n",
    "    features = []\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        detect_image = detect_face(image)\n",
    "        \n",
    "        if detect_image is None:\n",
    "            print('‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤')\n",
    "            return False\n",
    "        \n",
    "        features = generate_features(detect_image)\n",
    "\n",
    "        vectorizer = np.array(features)\n",
    "        final_vector = np.mean(vectorizer, axis=0) \n",
    "        \n",
    "        print(final_vector)\n",
    "\n",
    "        cursor.execute(\"INSERT INTO users (firstname, lastname, embedding) VALUES (?, ?, ?)\", \n",
    "                           (firstname, lastname, final_vector.tobytes()))\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_face(firstname, lastname, image_path):\n",
    "    features = []\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        detect_image = detect_face(image)\n",
    "        \n",
    "        if detect_image is None:\n",
    "            print('‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤')\n",
    "            return False\n",
    "        \n",
    "        features = generate_features(detect_image)\n",
    "\n",
    "        vectorizer = np.array(features)\n",
    "        final_vector = np.mean(vectorizer, axis=0) \n",
    "        \n",
    "        #print(vectorizer)\n",
    "        cursor.execute(\"SELECT embedding FROM users WHERE firstname = ? AND lastname = ?\", (firstname, lastname))\n",
    "        user_data = cursor.fetchall()\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        if not user_data:\n",
    "            print(\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö\")\n",
    "            return False\n",
    "        \n",
    "        # ‡∏î‡∏∂‡∏á embedding ‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "        db_embedding = user_data[0][0]  # ‡∏î‡∏∂‡∏á embedding ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ô‡πÅ‡∏£‡∏Å\n",
    "        db_embedding_np = np.frombuffer(db_embedding, dtype=np.float64)\n",
    "\n",
    "        cosine_similarity = dot(final_vector, db_embedding_np) / (norm(final_vector) * norm(db_embedding_np))\n",
    "        print(\"Cosine Similarity:\", cosine_similarity)\n",
    "\n",
    "        # ‡πÉ‡∏ä‡πâ cosine similarity ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à\n",
    "        if cosine_similarity > 0.6:  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î threshold ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á\n",
    "            print(f\"‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö {firstname} {lastname}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ: ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.4968624418820418\n",
      "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ: ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # register_face('Shuhua', 'Shuhua', 'Shuhua01.png')\n",
    "    login_face('Shuhua', 'Shuhua', 'Minnie02.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
